{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0426cfa4",
   "metadata": {},
   "source": [
    "# Str ouput parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1823cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rgukt/data/LangChain/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'mistralai/Mistral-7B-Instruct-v0.3',\n",
    "    task= 'text-generation',\n",
    "\n",
    ")\n",
    "model = ChatHuggingFace(llm= llm)\n",
    "\n",
    "#first prompt\n",
    "template1 = PromptTemplate(\n",
    "    template= \"write a detailed report on {topic} \",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# second prompt\n",
    "\n",
    "template2 = PromptTemplate(\n",
    "    template=\"write a 5 line summary on the following text . /n {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "Prompt1 = template1.invoke({'topic':\"black hole\"})\n",
    "\n",
    "result = model.invoke(Prompt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2359b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of course, I'd be happy to help! A black hole is a region in space where gravity is so strong that nothing, not even light, can escape from it. They are primarily characterized by their immense mass and the enormous gravitational pull they exert.\\n\\nBlack holes are formed when a massive star collapses in on itself, causing its core to become incredibly dense. This forms a singularity, a point with infinite density and zero volume. The boundary around a black hole within which the gravitational pull is so strong that nothing can escape is called the event horizon.\\n\\nThe visible part of a black hole is the accretion disk, which is formed when matter orbits a black hole and heats up due to friction. This heat emits X-rays, which can be observed by telescopes. However, the black hole itself is invisible because it does not emit or reflect any light.\\n\\nBlack holes have a significant impact on the universe. They can cause gravitational lensing, which is the bending of light around a massive object. This can be observed as a distortion in the appearance of distant galaxies. They also play a role in galaxy formation and evolution.\\n\\nSupermassive black holes, which are millions or billions of times more massive than the sun, are found at the centers of most galaxies, including our own Milky Way. Their exact role in galaxy formation and evolution is still a subject of ongoing research.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aee9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt2 = template2.invoke({'text':result.content})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5413e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=\"write a 5 line summary on the following text . /n Of course, I'd be happy to help! A black hole is a region in space where gravity is so strong that nothing, not even light, can escape from it. They are primarily characterized by their immense mass and the enormous gravitational pull they exert.\\n\\nBlack holes are formed when a massive star collapses in on itself, causing its core to become incredibly dense. This forms a singularity, a point with infinite density and zero volume. The boundary around a black hole within which the gravitational pull is so strong that nothing can escape is called the event horizon.\\n\\nThe visible part of a black hole is the accretion disk, which is formed when matter orbits a black hole and heats up due to friction. This heat emits X-rays, which can be observed by telescopes. However, the black hole itself is invisible because it does not emit or reflect any light.\\n\\nBlack holes have a significant impact on the universe. They can cause gravitational lensing, which is the bending of light around a massive object. This can be observed as a distortion in the appearance of distant galaxies. They also play a role in galaxy formation and evolution.\\n\\nSupermassive black holes, which are millions or billions of times more massive than the sun, are found at the centers of most galaxies, including our own Milky Way. Their exact role in galaxy formation and evolution is still a subject of ongoing research.\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(Prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50cff6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = model.invoke(Prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed1840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a quick summary:\n",
      "\n",
      "1. Black holes are regions in space with such strong gravity that nothing, not even light, can escape.\n",
      "2. They are formed when massive stars collapse, creating a singularity (a point with infinite density).\n",
      "3. The boundary around a black hole is the event horizon, beyond which nothing can escape.\n",
      "4. The visible part of a black hole is the accretion disk, where matter orbits and heats up, emitting X-rays.\n",
      "5. Black holes have significant impacts on the universe, causing effects like gravitational lensing and influencing galaxy formation and evolution.\n",
      "\n",
      "Supermassive black holes, far more massive than the sun, are found at the centers of most galaxies, including our own Milky Way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395305e",
   "metadata": {},
   "source": [
    "## Making Chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86615fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20ae9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = chain.invoke({'topic':\"black hole\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6d01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Black Holes: Cosmic Vacuum Cleaners - A Detailed Report \n",
      "\n",
      "Black holes are celestial objects of immense gravity, so intense that nothing, not even light, can escape their grasp. They represent some of the most fascinating and intriguing phenomena in the universe, and understanding them requires navigating the culminations of Einstein's Theory of Relativity and concepts of spacetime.\n",
      "\n",
      "**Understanding the Basics:**\n",
      "\n",
      "* **Formation:** Black holes are formed when massive stars collapse at the end of their lives.  This happens when the outward pressure of a star's nuclear fusion force fails to overcome the inward pull of gravity, collapsing the star's core into an infinitely small point — a singularity. The remaining mass creates a region of gravitational pull so strong that even light (with its highest energy) cannot escape its pull.\n",
      "* **Types:** Black holes are categorized based on their mass.\n",
      "    * **Stellar-mass black holes:** Formed from the collapse of a single, massive star. These are the most common type.\n",
      "    * **Supermassive black holes:** Millions, even billions, of times the mass of our Sun, found at the centers of galaxies. Their origins are still under active research.\n",
      "    * **Intermediate Black Holes:** Typically rarer, these could fall somewhere between stellar and supermassive black holes.\n",
      "\n",
      "**Detecting the Invisible:**\n",
      "\n",
      "* **Event Horizon:** The boundary around a black hole beyond which even light cannot escape. It is the \"point of no return\" where escaping becomes impossible. \n",
      "* **Hawking Radiation:** Proposed by Stephen Hawking, this theory suggests that black holes slowly emit radiation due to quantum effects. \n",
      "* **Accretion Discs:**  As matter falls towards a black hole, it forms a disk of intense heat and light surrounding it. This creates a \"bright spot\" visible across vast distances.\n",
      "* **Gravitational Waves:**  When two black holes combine, their gravitational pull ripples through spacetime, producing waves that can stretch and compress the fabric of the universe. These ripples are detected by ground-based observatories like LIGO.\n",
      "\n",
      "\n",
      "**Black Hole Gravity:**\n",
      "\n",
      "* **Curvature of spacetime:** Gravity is not a force in the traditional sense, but rather the result of the curvature of spacetime caused by massive objects.  Black holes possess such intense mass that they warp the fabric of spacetime dramatically, creating a profound and inescapable gravitational well.\n",
      "* **Time dilation and gravitational redshift:** The stronger the gravitational pull, the slower time passes near the black hole. This effect is stunning and appears paradoxical—time would slow down significantly near a black hole! Light also experiences redshift, meaning its light waves stretch and appear redder as they are pulled towards the black hole.\n",
      "* **Black hole singularity:** The center of a black hole, where the density and curvature of spacetime become infinitely large, and our understanding of physics breaks down as we approach that point.\n",
      "\n",
      "\n",
      "**Future Research and Significance:**\n",
      "\n",
      "* **Observational limitations:**  Despite direct observation being challenging, scientists continually refine theoretical models and techniques for observing black holes. \n",
      "* **Signaling anomalies:**  Studying extreme environments like black holes might offer evidence of gravity's deeper mysteries, potentially a response to the perplexing \"landscape\" of multiple universes.\n",
      "* **Impact on understanding of cosmology:** Black holes play a crucial role within our understanding of the Universe's history, evolution, and structure. Their influence on galaxy formation and evolution profoundly impacts cosmic understanding.\n",
      "\n",
      "\n",
      "**Beyond Western Science:**\n",
      "\n",
      "* **Confronting Cultural Representations:** Despite its current scientific acceptance, the image of a black hole often recited in popular culture carries diverse and sometimes misleading stereotypes. It's essential to understand the scientific understanding of black holes provides a profound framework for comprehending these unique celestial phenomena and what they mean for our understanding of the universe.\n",
      "\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Black holes are fascinating and complex objects that continue to challenge our understanding of physics, gravity, and the universe as a whole. Further research and observation are crucial for unlocking their secrets, particularly concerning their potential connections to our understanding of quantum mechanics and other unknown substances in our universe.  \n",
      "\n",
      "\n",
      "**Need for further investigation topics:**\n",
      "\n",
      "* The exact nature of the black hole singularity. \n",
      "* How \"Hawking Radiation\" actually changes the fabric of reality.\n",
      "*  The information paradox: What happens to information that falls into a black hole? \n",
      "* Predicting the final fate of black holes and their environmental effects on their surroundings.\n",
      "\n",
      "\n",
      "This report aims to provide a detailed overview of black holes, emphasizing their importance in modern physics and scientific research. The quest to fully understand these elusive objects is both intellectually invigorating and provides unique insights into the universe's vast secrets. \n",
      "\n",
      "Here's a 5-line summary of the provided text:\n",
      "\n",
      "1. **Black holes are cosmic vacuum cleaners:** Formed by the collapse of massive stars, they possess immense gravity so strong even light can't escape their pull.\n",
      "2. **They come in different sizes:** Stellar-mass black holes are common, supermassive black holes form the centers of galaxies, while intermediate black holes are rarer.\n",
      "3. **Detection relies on indirect evidence:** Observations focus on the event horizon, accretion disks, gravitational waves, and Hawking radiation.\n",
      "4. **Black holes distort spacetime:**  Their massive gravity creates a warping that affects time and light due to powerful gravitational effects. \n",
      "5. **Future research is vital:**  Understanding black holes helps us explore fundamental physics, the universe's evolution, and even its potential connection to multiple universes. \n",
      "\n",
      "\n",
      "Let me know if you'd like me to focus on any specific aspects!  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'google/gemma-2-2b-it',\n",
    "    task= 'text-generation',\n",
    "\n",
    ")\n",
    "model = ChatHuggingFace(llm= llm)\n",
    "\n",
    "#first prompt\n",
    "template1 = PromptTemplate(\n",
    "    template= \"write a detailed report on {topic} \",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# second prompt\n",
    "\n",
    "template2 = PromptTemplate(\n",
    "    template=\"write a 5 line summary on the following text . /n {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "Prompt1 = template1.invoke({'topic':\"black hole\"})\n",
    "\n",
    "result = model.invoke(Prompt1)\n",
    "\n",
    "print(result.content)\n",
    "\n",
    "Prompt2 = template2.invoke(result.content)\n",
    "\n",
    "result2 = model.invoke(Prompt2)\n",
    "\n",
    "print(result2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b860117",
   "metadata": {},
   "source": [
    "### starting with parser and chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cbd55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'google/gemma-2-2b-it',\n",
    "    task= 'text-generation',\n",
    "\n",
    ")\n",
    "model = ChatHuggingFace(llm= llm)\n",
    "\n",
    "#first prompt\n",
    "template1 = PromptTemplate(\n",
    "    template= \"write a detailed report on {topic} \",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# second prompt\n",
    "\n",
    "template2 = PromptTemplate(\n",
    "    template=\"write a 5 line summary on the following text . /n {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "chain = template1 | model | parser | template2 | model | parser\n",
    "\n",
    "result3 = chain.invoke({'topic':'india'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1475daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a 5-line summary:\n",
      "\n",
      "India is a rapidly developing nation with a long and complex history, rich culture, and thriving economy.  Though challenged by poverty and inequality, it possesses vast potential fueled by its young population and entrepreneurial spirit. Advances in technology and digital literacy alongside a focus on sustainability indicate India's future impact on the global scene.  However, addressing societal injustices and fostering a more equitable society will be key to realizing its full potential. India faces a challenging but hopeful path toward a brighter future. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d3ab5",
   "metadata": {},
   "source": [
    "## json output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9841583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "from dotenv import  load_dotenv\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'google/gemma-2-2b-it',\n",
    "    task= 'text-generation',\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template1 = PromptTemplate(\n",
    "    template= \"Give the name,age and city of a fictional person \\n {format_instruction}\",\n",
    "\n",
    "    input_variables= [],\n",
    "\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a443df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acc1b077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the name,age and city of a fictional person \n",
      " Return a JSON object.\n"
     ]
    }
   ],
   "source": [
    "print(template1.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad7a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template1.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed9fb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cc2111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"name\": \"Aiko Tanaka\",\\n  \"age\": 27,\\n  \"city\": \"Kyoto, Japan\"\\n}\\n``` \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 27, 'total_tokens': 67}, 'model_name': 'google/gemma-2-2b-it', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--c7dd6674-de64-459e-8979-9bb2759a3492-0' usage_metadata={'input_tokens': 27, 'output_tokens': 40, 'total_tokens': 67}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54ca4d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Aiko Tanaka\",\n",
      "  \"age\": 27,\n",
      "  \"city\": \"Kyoto, Japan\"\n",
      "}\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4887c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Aiko Tanaka', 'age': 27, 'city': 'Kyoto, Japan'}\n"
     ]
    }
   ],
   "source": [
    "final_result = parser.parse(result.content)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d771bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template1 | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({})# while calling with chain we have to pass the dict as there is not input varibles so that we given the empty dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4451b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Eleanor Vance', 'age': 37, 'city': 'Cape Canaveral, Florida'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a5769",
   "metadata": {},
   "source": [
    "Perfect, thanks for sharing the updated code 🙌\n",
    "Let’s walk through exactly what this does.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **LLM Setup**\n",
    "\n",
    "```python\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='google/gemma-2-2b-it',\n",
    "    task='text-generation',\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "```\n",
    "\n",
    "* You’re calling the **Gemma-2-2B-Instruct** model from Hugging Face via their Inference API.\n",
    "* Wrapping it with `ChatHuggingFace` makes it behave like a chat model inside LangChain.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **JSON Parser**\n",
    "\n",
    "```python\n",
    "parser = JsonOutputParser()\n",
    "```\n",
    "\n",
    "* `JsonOutputParser` is a LangChain helper that enforces the model’s output to be **valid JSON**.\n",
    "* It also provides **formatting instructions** (like a schema) that you can embed in your prompt so the model knows exactly how to answer.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Prompt Template**\n",
    "\n",
    "```python\n",
    "template1 = PromptTemplate(\n",
    "    template=\"Give the name,age and city of a fictional person \\n {format_instruction}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions}\n",
    ")\n",
    "```\n",
    "\n",
    "Here’s what happens step by step:\n",
    "\n",
    "* `template=\"...\"`\n",
    "  → This is the raw instruction you’ll send to the LLM. Notice the placeholder `{format_instruction}` inside it.\n",
    "\n",
    "* `input_variables=[]`\n",
    "  → Means you’re not passing any runtime variables — the template is static.\n",
    "\n",
    "* `partial_variables={'format_instruction': parser.get_format_instructions}`\n",
    "  → This automatically fills `{format_instruction}` with the JSON schema guidance from `JsonOutputParser`.\n",
    "\n",
    "So, if you print `parser.get_format_instructions()`, you’ll see something like:\n",
    "\n",
    "```\n",
    "The output should be a JSON object with the following format:\n",
    "{\n",
    "    \"name\": string,\n",
    "    \"age\": integer,\n",
    "    \"city\": string\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **What `print(template1)` Shows**\n",
    "\n",
    "When you run:\n",
    "\n",
    "```python\n",
    "print(template1)\n",
    "```\n",
    "\n",
    "You won’t get the **fully formatted prompt text** yet. Instead, you’ll see an object representation like:\n",
    "\n",
    "```\n",
    "PromptTemplate(input_variables=[], output_parser=None, partial_variables={'format_instruction': '...'})\n",
    "```\n",
    "\n",
    "To see the **final prompt text** (with `{format_instruction}` replaced), you need to call:\n",
    "\n",
    "```python\n",
    "print(template1.format())\n",
    "```\n",
    "\n",
    "That would output something like:\n",
    "\n",
    "```\n",
    "Give the name,age and city of a fictional person\n",
    "The output should be a JSON object with the following format:\n",
    "{\"name\": string, \"age\": integer, \"city\": string}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Summary:**\n",
    "\n",
    "* You built a prompt that asks for a fictional person’s details.\n",
    "* You also inject **formatting instructions** from `JsonOutputParser`, so the model knows to return JSON.\n",
    "* `print(template1)` just shows the object, but `print(template1.format())` shows the **real final prompt** you’ll send to the model.\n",
    "\n",
    "---\n",
    "\n",
    "Do you want me to extend this so you can **actually run the prompt through the model and get a parsed Python dictionary** as output (instead of raw text)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7e3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "528de268",
   "metadata": {},
   "source": [
    "Great question 👍 — JSON output is super useful when you want structured data from an LLM, but it does come with some **drawbacks and limitations** you should be aware of.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔴 Drawbacks of JSON Output from LLMs\n",
    "\n",
    "### 1. **LLMs are not strict JSON generators**\n",
    "\n",
    "* Hugging Face text-generation models (like Gemma, Mistral, LLaMA, etc.) don’t have a built-in *“JSON mode”* like OpenAI does.\n",
    "* This means the model might:\n",
    "\n",
    "  * Add extra text (e.g., `\"Here is the result:\"` before the JSON).\n",
    "  * Produce malformed JSON (missing quotes, trailing commas, unescaped characters).\n",
    "  * Return partial or cut-off JSON if the output is too long.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Schema adherence is not guaranteed**\n",
    "\n",
    "* Even if you give formatting instructions, the model may:\n",
    "\n",
    "  * Return unexpected field names (`\"full_name\"` instead of `\"name\"`).\n",
    "  * Put values in the wrong type (`\"twenty\"` instead of `20`).\n",
    "  * Omit required fields.\n",
    "\n",
    "You usually need **validators (like Pydantic)** + retries to fix these cases.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Brittleness of prompts**\n",
    "\n",
    "* If your prompt is even slightly unclear, the model may ignore JSON instructions.\n",
    "* Example: if you say *“Write a review in JSON format and also explain why”*, the model might add an English explanation *outside* the JSON.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Token limits and truncation**\n",
    "\n",
    "* JSON can get large if you’re extracting lots of structured fields.\n",
    "* On long outputs, the model may truncate mid-JSON, leaving invalid results.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Parsing overhead**\n",
    "\n",
    "* You always need a parsing layer (`JsonOutputParser`, `pydantic`, `json.loads()`) to validate/fix.\n",
    "* This adds extra processing + sometimes retries, which slows things down.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Model-dependent reliability**\n",
    "\n",
    "* Some models (like GPT-4, Claude, or Llama-3 Instruct) follow JSON instructions pretty well.\n",
    "* Smaller ones (like Gemma-2B, Mistral-7B) are much less reliable and may frequently break JSON formatting.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **In short:**\n",
    "\n",
    "* JSON output is great for structured pipelines.\n",
    "* But with Hugging Face text-generation models, it’s **not guaranteed to be valid or consistent**. You’ll need error handling, validation, and sometimes re-prompting to make it production-ready.\n",
    "\n",
    "---\n",
    "\n",
    "👉 Do you want me to show you how to build a **retry + correction loop** so that if the model outputs invalid JSON, LangChain will automatically fix it and still return a valid Python object?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017bbce",
   "metadata": {},
   "source": [
    "# Structured output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e06997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c39ff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "from dotenv import  load_dotenv\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'google/gemma-2-2b-it',\n",
    "    task= 'text-generation',\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "schema = [\n",
    "    ResponseSchema(name = 'fact_1', description= 'Fact_1 about the topic'),\n",
    "    ResponseSchema(name = 'fact_2', description= 'Fact_2 about the topic'),\n",
    "    ResponseSchema(name = 'fact_3', description= 'Fact_3 about the topic'),\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"Give me the three facts about the {topic} \\n {format_instruction}\",\n",
    "    input_variables=['topic'],\n",
    "    partial_variables= {'format_instruction':parser.get_format_instructions}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42373dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseSchema(name='fact_1', description='Fact_1 about the topic', type='string'),\n",
       " ResponseSchema(name='fact_2', description='Fact_2 about the topic', type='string'),\n",
       " ResponseSchema(name='fact_3', description='Fact_3 about the topic', type='string')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f419dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_schemas=[ResponseSchema(name='fact_1', description='Fact_1 about the topic', type='string'), ResponseSchema(name='fact_2', description='Fact_2 about the topic', type='string'), ResponseSchema(name='fact_3', description='Fact_3 about the topic', type='string')]\n"
     ]
    }
   ],
   "source": [
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebc05939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['topic'] input_types={} partial_variables={'format_instruction': <bound method StructuredOutputParser.get_format_instructions of StructuredOutputParser(response_schemas=[ResponseSchema(name='fact_1', description='Fact_1 about the topic', type='string'), ResponseSchema(name='fact_2', description='Fact_2 about the topic', type='string'), ResponseSchema(name='fact_3', description='Fact_3 about the topic', type='string')])>} template='Give me the three facts about the {topic} \\n {format_instruction}'\n"
     ]
    }
   ],
   "source": [
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdaa7747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"fact_1\": string  // Fact_1 about the topic\\n\\t\"fact_2\": string  // Fact_2 about the topic\\n\\t\"fact_3\": string  // Fact_3 about the topic\\n}\\n```'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c1249db",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | model | parser \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45847646",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({'topic':'india'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fact_1': 'India is the seventh-most-populated country in the world with over 1.4 billion inhabitants.', 'fact_2': 'The Indian subcontinent is home to a diverse array of wildlife, including endangered species like the Bengal Tiger and the Asian Elephant.', 'fact_3': 'The Taj Mahal, an iconic white marble mausoleum built in Agra, is one of the Seven Wonders of the World.'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a6fc2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('fact_1', 'India is the seventh-most-populated country in the world with over 1.4 billion inhabitants.'), ('fact_2', 'The Indian subcontinent is home to a diverse array of wildlife, including endangered species like the Bengal Tiger and the Asian Elephant.'), ('fact_3', 'The Taj Mahal, an iconic white marble mausoleum built in Agra, is one of the Seven Wonders of the World.')])\n"
     ]
    }
   ],
   "source": [
    "print(result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a5a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_1 India is the seventh-most-populated country in the world with over 1.4 billion inhabitants.\n",
      "fact_2 The Indian subcontinent is home to a diverse array of wildlife, including endangered species like the Bengal Tiger and the Asian Elephant.\n",
      "fact_3 The Taj Mahal, an iconic white marble mausoleum built in Agra, is one of the Seven Wonders of the World.\n"
     ]
    }
   ],
   "source": [
    "for key,value in result.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1da257",
   "metadata": {},
   "source": [
    "## Pydantic output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a13d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Priya Sharma\",\n",
      "  \"age\": 28,\n",
      "  \"city\": \"Mumbai\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='deepseek-ai/DeepSeek-V3.1-Terminus',\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name : str = Field(description='Name of the person')\n",
    "    age: int = Field(description=\"Age of the person\")\n",
    "    city: str = Field(description=\"Name of the city the person belongs to\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"Genarate the name, age and city of a fictional {place} person \\n {format_instruction}\",\n",
    "    input_variables=['place'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "prompt = template.invoke({'place':\"Indian\"})\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7af927da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\n  \"name\": \"Priya Sharma\",\\n  \"age\": 28,\\n  \"city\": \"Mumbai\"\\n}', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 236, 'total_tokens': 262}, 'model_name': 'deepseek-ai/DeepSeek-V3.1-Terminus', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run--b38bd4b2-2ae9-4e3b-a3f8-0166e30ff3d3-0', usage_metadata={'input_tokens': 236, 'output_tokens': 26, 'total_tokens': 262})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7dd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Genarate the name, age and city of a fictional Indian person \\n The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"Name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"Age of the person\", \"title\": \"Age\", \"type\": \"integer\"}, \"city\": {\"description\": \"Name of the city the person belongs to\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"name\", \"age\", \"city\"]}\\n```'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62f3f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"John Doe\",\n",
      "    \"age\": 45,\n",
      "    \"is_employed\": true,\n",
      "    \"address\": {\n",
      "        \"street\": \"123 Main St\",\n",
      "        \"city\": \"Anytown\",\n",
      "        \"zip_code\": \"12345\"\n",
      "    },\n",
      "    \"skills\": [\n",
      "        \"Python\",\n",
      "        \"Data Analysis\",\n",
      "        \"SQL\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sample Python dictionary\n",
    "data = {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"age\": 45,\n",
    "    \"is_employed\": True,\n",
    "    \"address\": {\n",
    "        \"street\": \"123 Main St\",\n",
    "        \"city\": \"Anytown\",\n",
    "        \"zip_code\": \"12345\"\n",
    "    },\n",
    "    \"skills\": [\"Python\", \"Data Analysis\", \"SQL\"]\n",
    "}\n",
    "\n",
    "# Pretty print with 4 spaces indentation\n",
    "pretty_json = json.dumps(data, indent=4)\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Genarate the name, age and city of a fictional Indian person \\n The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"name\\\": {\\\"description\\\": \\\"Name of the person\\\", \\\"title\\\": \\\"Name\\\", \\\"type\\\": \\\"string\\\"}, \\\"age\\\": {\\\"description\\\": \\\"Age of the person\\\", \\\"title\\\": \\\"Age\\\", \\\"type\\\": \\\"integer\\\"}, \\\"city\\\": {\\\"description\\\": \\\"Name of the city the person belongs to\\\", \\\"title\\\": \\\"City\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"name\\\", \\\"age\\\", \\\"city\\\"]}\\n```\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7100cd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Priya Sharma' age=28 city='Mumbai'\n"
     ]
    }
   ],
   "source": [
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({\"place\":\"indian\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e19b7",
   "metadata": {},
   "source": [
    "Pydantic provide the instruction and the also provide the validation of the ouput from the llm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
