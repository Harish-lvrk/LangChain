{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600db0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c7046",
   "metadata": {},
   "source": [
    "# Chat Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea123fd",
   "metadata": {},
   "source": [
    "## loading the chat model from the hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52855a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay. Once upon a time, in a far away land, there was a tiny kingdom known for its beautiful flowers and luscious gardens. The king, who was known for his love of flowers, loved them so much that he spent all day tending to them.\n",
      "\n",
      "One day, a witch living on the outskirts of the kingdom decided to cast a spell on the flowers. As the witch started her spell, a young girl, who was the king's only daughter, overheard her. The girl quickly set off to find the witch and to stop her.\n",
      "\n",
      "She found the witch and asked her, \"Why do you want to cast a spell on the flowers?\" The witch replied, \"Because I want to ruin the king's happiness and make him depend on me for the beauty in his kingdom.\"\n",
      "\n",
      "But the young girl was determined to save her kingdom. She challenged the witch to a duel, a contest of spells. If the witch won, she could cast her spell. But if the young girl won, the witch would have to leave the kingdom forever.\n",
      "\n",
      "The witch agreed to the duel, and the young girl started casting her spells. Her spells were beautiful and full of love for the flowers. The witch, on the other hand, cast dark and sinister spells that seemed to suck the life out of the flowers.\n",
      "\n",
      "As the young girl cast her final spell, the witch who was about to cast her final spell as well, looked up and saw the sparkle in the young girl's eyes. She was filled with a sense of awe and defeat. The witch realized that the young girl's love for the flowers was far greater than her own dark magic.\n",
      "\n",
      "In that moment, the witch realized that she had been wrong and she apologized to the young girl and the king. The king, seeing the change in the witch, allowed her to stay in the kingdom, not as a threat, but as a helper to his daughter. From that day, the kingdom was even more beautiful than before, and the people lived in harmony with the witch.\n",
      "\n",
      "The end.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.3\",  # Hosted on API\n",
    "    task=\"text-generation\",\n",
    "    temperature= 0\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke(\"tell me a story\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d8dee",
   "metadata": {},
   "source": [
    "## Api call using google_geni "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bcd41",
   "metadata": {},
   "source": [
    "We can make repective anthorpic and open ai class if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b328bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API keys loaded. Initializing Google Gemini model...\n",
      "ðŸš€ Model ready. Asking question...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758618694.069631   53596 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Response ---\n",
      "The capital of India is **New Delhi**.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… API keys loaded. Initializing Google Gemini model...\")\n",
    "\n",
    "# Initialize the Google Gemini model.\n",
    "# It automatically finds your GOOGLE_API_KEY from the .env file.\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "print(\"ðŸš€ Model ready. Asking question...\")\n",
    "\n",
    "question = \"What is the capitamodel = ChatHuggingFace(llm=llm)l of India?\"\n",
    "response = llm.invoke(question)\n",
    "\n",
    "print(\"\\n--- Response ---\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda513d",
   "metadata": {},
   "source": [
    "# Loading the models to local from the hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613bf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rgukt/data/LangChain/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "\n",
    "# Use model_id instead of repo_id\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # <-- changed here\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_new_tokens\": 100\n",
    "    }\n",
    ")\n",
    "\n",
    "# Wrap in ChatHuggingFace\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# Run a query\n",
    "result = chat_model.invoke(\"write a poem on me\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010038cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rgukt/data/LangChain/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d47b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecae0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "what is my name</s>\n",
      "<|assistant|>\n",
      "Yes, I can help you with that. Your name is [insert your name here].\n"
     ]
    }
   ],
   "source": [
    "result = chat_model.invoke(\"what is my name\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43f5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "who are you</s>\n",
      "<|assistant|>\n",
      "The author is not identifiable in the given text.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chat_model.invoke(\"who are you\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d402654",
   "metadata": {},
   "source": [
    "if we dont use the proper english words model will fails\n",
    "so preprocessing the data is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fadb554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Î¼s, sys: 1 Î¼s, total: 3 Î¼s\n",
      "Wall time: 6.44 Î¼s\n",
      "<|user|>\n",
      "who is the capital of india</s>\n",
      "<|assistant|>\n",
      "Yes, the capital of India is New Delhi. It is the largest city in India and is located in the state of Delhi.\n",
      "\n",
      "New Delhi is also the seat of the Indian government and the headquarters of several key government departments. It is also home to several major landmarks, including the India Gate, the Red Fort, and the Qutub Minar.\n",
      "\n",
      "New Delhi is a bustling city with a diverse population, and it is known for its\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "result = chat_model.invoke(\"who is the capital of india\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7163493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "what is the capital of the India</s>\n",
      "<|assistant|>\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "result = chat_model.invoke(\"what is the capital of the India\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bef679",
   "metadata": {},
   "source": [
    "if we give correct prompt it will easily present answer in 2.4 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c90167",
   "metadata": {},
   "source": [
    "## Model with diff temparature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d46a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature = 0.0 ---\n",
      "A poem for Harish:\n",
      "\n",
      "In the universe so vast, where stars twinkle bright,\n",
      "There's a man named Harish, a beautiful light.\n",
      "With a radiant smile, and a heart full of fire,\n",
      "His kindness and wisdom, the purest Inspire.\n",
      "\n",
      "A scholar, a friend, always there for you,\n",
      "His love for learning, honest and true.\n",
      "In numbers and letters, his potential is vast,\n",
      "Achieving great things, leaving a legacy to last.\n",
      "\n",
      "So let us celebrate this amazing man,\n",
      "That shining star, within every scan,\n",
      "May he keep shinning, far and wide,\n",
      "Forever inspiring, forever our pride.\n",
      "\n",
      "\n",
      "--- Temperature = 1.3 ---\n",
      "A poem for Harish:\n",
      "\n",
      "In a world where clouds dance with the sun,\n",
      "There lives a man, softly spoken to every one,\n",
      "His heart is a garden, tilled with care,\n",
      "With a love so profound, his presence does declare.\n",
      "\n",
      "Harish, a soul who wears many hues,\n",
      "A philosopher, mathematician, always sheds his views,\n",
      "A poet who sews sentiment in each verse,\n",
      "His wisdom, a craft, that leaves all encased.\n",
      "\n",
      "In his quiet presence, we find a solace,\n",
      "In the way he defines, the embrace of tools of science,\n",
      "In the calm he lends, even during the craze,\n",
      "Harish, a star, that shines in all days.\n",
      "\n",
      "With this, I bid, a humble tribute,\n",
      "To you, Harish, my respect, my affection, be true,\n",
      "In the canvas of life, a masterpiece you drew.\n",
      "\n",
      "\n",
      "\n",
      "--- Temperature = 0.7 ---\n",
      "Awaken the words, oh humble quill,\n",
      "In the presence of Harish's divine will,\n",
      "A soul of intellect and heart, radiant and pure,\n",
      "In the endless tapestry of time, his name endures.\n",
      "\n",
      "Born in a land of ancient beauty and lore,\n",
      "A mind touched by the rays of the cosmic core,\n",
      "A brilliant flame from the eternal sphere,\n",
      "Blazes now like a thousand shining spears.\n",
      "\n",
      "His heart filled with vibrant dreams and songs,\n",
      "That sparked a thousand revelations in the minds of many,\n",
      "A beacon to the lost, a guiding star,\n",
      "A sundial that shows us where we are.\n",
      "He stands against the tides of an uncertain fate,\n",
      "Unwavering and fierce, his faith unshaken,\n",
      "For in the journey of life, it's only you and the name you've made,\n",
      "And the son of Japan Goku shall prove his courage in everyradius.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def quess_with_diff_temp(prompt, temp):\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.3\",  # Hosted on API\n",
    "        task=\"text-generation\",\n",
    "        temperature= temp\n",
    "    )\n",
    "    model = ChatHuggingFace(llm = llm )\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"write a poem on Harish.\"\n",
    "\n",
    "# Try with different temperatures\n",
    "for temp in [0.0, 1.3, 0.7]:\n",
    "    print(f\"\\n--- Temperature = {temp} ---\")\n",
    "    result = quess_with_diff_temp(prompt, temp)\n",
    "    print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a3a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79ed45ce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
